

# planet/scripts/train.py
def start(logdir, args):
def resume(logdir, args):
def process(logdir, config, args):

def main(args):
    experiment = training.Experiment(
        process_fn=functools.partial(process, args=args),
        start_fn=functools.partial(start, args=args),
        resume_fn=functools.partial(resume, args=args), ...)

    for run in experiment:          # the method __iter__(self) defined in experiment.
        for unused_score in run:    # the method __iter__(self) defined in run.
            pass

class Experiment(object):
    def __iter__(self):

num_runs

# planet/training/running.py
class Run(object):
    def __iter__(self):
        """Iterate over the process function and finalize the log directory."""
        args = self._init_fn and self._init_fn(self._logdir)


        # planet/scripts/train.py
        def start(logdir, args):
            config = getattr(configs, args.config)(config, args.params)  # configs.(args.config) = configs.default, task is defined.
            training.utility.collect_initial_episodes(config)

            # planet/training/utility.py
            def collect_initial_episodes(config):
                control.random_episodes(...)

                # planet/control/random_episodes.py
                def random_episodes(env_ctor, num_episodes, output_dir=None):
                    env = env_ctor()
                    env = wrappers.CollectGymDataset(env, output_dir)
                    obs = env.reset()
                    while not done:
                        obs, _, done, info = env.step(action)


        for value in self._process_fn(self._logdir, *args):
            if not self._running[0]:
                break
            yield value


        # planet/scripts/train.py
        def process(logdir, config, args):
            dataset = tools.numpy_episodes(...)
            for score in training.utility.train(training.define_model, dataset, logdir, config):
                yield score

            # planet/training/utility.py
            def train(model_fn, datasets, logdir, config):
                trainer = trainer_.Trainer(logdir, config=config)        #  trainer_ is trainer.py
                data = get_batch(datasets, trainer.phase, trainer.reset)
                score, summary = model_fn(data, trainer, config)         #  model_fn is training.define_model.
                trainer.add_phase(...)
                trainer.add_phase(...)
                for score in trainer.iterate(config.max_steps):
                    yield score

                # planet/training/trainer.py
                class Trainer(object):
                    def iterate(self, max_step=None, sess=None):
                        while True:   # MAIN LOOP
                            global_step = sess.run(self._global_step)
                            if max_step and global_step >= max_step:
                                break
                            summary, mean_score, global_step = sess.run(phase.op, phase.feed)
                            if self._is_every_steps(phase_step, phase.batch_size, phase.report_every):
                                tf.logging.info('Score {}.'.format(mean_score))
                                yield mean_score




env.py
ENV_CONFIG = {
    ...
    "x_res": 128, #64,  # cv2.resize()
    "y_res": 128, #64,  # cv2.resize()
    ...
    }

tasks.py
def _dm_control_env_carla(action_repeat, max_length, env_name):
(128, 128)

conv_ha.py
assert mean.shape[1:].as_list() == [128, 128, 3], mean.shape


# planet/control/simulate.py
def collect_rollouts():
    ...
    def simulate_fn():
        ...
    done, score, image, action, reward = tf.scan( simulate_fn, tf.range(duration),initializer, parallel_iterations=1)



# planet/scripts/tasks.py
def _dm_control_env_carla(action_repeat, max_length, env_name, img_size):
    env = control.wrappers.ExternalProcess(env_ctor)

    # planet/control/wrappers.py
    class ExternalProcess(object):
        def __init__(self, constructor):
            self._process = multiprocessing.Process(target=self._worker, args=(constructor, conn))
            self._process.start()

            # planet/control/wrappers.py
            def _worker(self, constructor, conn):
                result = getattr(env, name)(*args, **kwargs)

                # name = 'reset'
                # planet/control/wrappers.py
                class ConvertTo32Bit(object):
                    def reset(self):
                        observ = self._env.reset()

                # name = 'observation_sapce'
                # planet/control/wrappers.py
                class ConvertTo32Bit(object):
                    def __getattr__(self, name):
                        return getattr(self._env, name)

                        # planet/control/wrappers.py
                        class PixelObservations(object):
                            @property
                            high = {np.uint8: 255, np.float: 1.0}[self._dtype]
                            image = gym.spaces.Box(0, high, self._size + (3,), dtype=self._dtype)
                            ...
